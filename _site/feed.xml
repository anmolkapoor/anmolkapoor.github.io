<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="3.7.4">Jekyll</generator><link href="http://anmolkapoor.in/feed.xml" rel="self" type="application/atom+xml" /><link href="http://anmolkapoor.in/" rel="alternate" type="text/html" /><updated>2019-10-30T13:00:19+05:30</updated><id>http://anmolkapoor.in/feed.xml</id><title type="html">Anmol Kapoor</title><subtitle>~Working on tag line~</subtitle><author><name>Anmol Kapoor</name></author><entry><title type="html">Create and Inference Bayesian Networks using Pgmpy with Example</title><link href="http://anmolkapoor.in/2019/05/05/Inference-Bayesian-Networks-Using-Pgmpy-With-Social-Moderator-Example/" rel="alternate" type="text/html" title="Create and Inference Bayesian Networks using Pgmpy with Example" /><published>2019-05-05T00:00:00+05:30</published><updated>2019-05-05T00:00:00+05:30</updated><id>http://anmolkapoor.in/2019/05/05/Inference-Bayesian-Networks-Using-Pgmpy-With-Social-Moderator-Example</id><content type="html" xml:base="http://anmolkapoor.in/2019/05/05/Inference-Bayesian-Networks-Using-Pgmpy-With-Social-Moderator-Example/">&lt;p&gt;In this quick notebook, we will be discussing Bayesian Statisitcs over Bayesian Networks and Inferencing them using Pgmpy Python library.
Bayesian statistics is a theory in the field of statistics based on the Bayesian interpretation of probability where probability expresses a degree of belief in an event, which can change as new information is gathered, rather than a fixed value based upon frequency or propensity.Bayesian statistical methods use Bayes’ theorem to compute and update probabilities after obtaining new data. Bayes’ theorem describes the conditional probability of an event based on data as well as prior information or beliefs about the event or conditions related to the event.&lt;/p&gt;

&lt;h1 id=&quot;bayes-theorem&quot;&gt;Bayes’ theorem&lt;/h1&gt;
&lt;p&gt;Bayes’ theorem is a fundamental theorem in Bayesian statistics, as it is used by Bayesian methods to update probabilities, which are degrees of belief, after obtaining new data. Given two events A and B, the conditional probability of A given that B is true is expressed as follows:
&lt;img src=&quot;https://github.com/anmolkapoor/inference-bayesian-networks-using-pgmpy-example-social-media-moderator/raw/master/images/bayes_theorem.png&quot; alt=&quot;Bayes Theorem&quot; /&gt;&lt;/p&gt;

&lt;p&gt;The probability of the evidence P(B) can be calculated using the law of total probability. If &lt;img src=&quot;https://github.com/anmolkapoor/inference-bayesian-networks-using-pgmpy-example-social-media-moderator/raw/master/images/A_values.png&quot; alt=&quot;A values&quot; /&gt; is a partition of the sample space, which is the set of all outcomes of an experiment, then:
&lt;img src=&quot;https://github.com/anmolkapoor/inference-bayesian-networks-using-pgmpy-example-social-media-moderator/raw/master/images/total_probability.png&quot; alt=&quot;total probs&quot; /&gt;&lt;/p&gt;

&lt;h1 id=&quot;bayesian-network&quot;&gt;Bayesian network&lt;/h1&gt;
&lt;p&gt;A Bayesian network is a probabilistic graphical model (a type of statistical model) that represents a set of variables and their conditional dependencies via a directed acyclic graph (DAG). Bayesian networks are ideal for taking an event that occurred and predicting the likelihood that any one of several possible known causes was the contributing factor.&lt;/p&gt;

&lt;h1 id=&quot;example&quot;&gt;Example&lt;/h1&gt;
&lt;h3 id=&quot;statistical-moderator-for-social-platform-with-a-given-information-such-as-user-history-ml-model-prediction-other-user-flagging-the-content-etc&quot;&gt;Statistical moderator for social platform with a given information such as user history, ML model prediction, other user flagging the content, etc&lt;/h3&gt;
&lt;p&gt;We can use bayes rule and total probability theorem to infer probabilites in a bayes network. Lets take an example:&lt;/p&gt;

&lt;p&gt;Example
Lets consider an example, where a social media website wish to moderate content on the site and suspends bad user accounts. For this they would like us to create a statistical moderator that can take the preemtive measure based on information given. Lets assume we have following information:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;M : A prediction from a ML model that can read the content and give a score (probability) that this content should be flagged.&lt;/li&gt;
  &lt;li&gt;U :  Another User flags the content.&lt;/li&gt;
  &lt;li&gt;B : The account was suspended before for any bad content.&lt;/li&gt;
  &lt;li&gt;R : Score (Probability) that the content should be removed from the platform.&lt;/li&gt;
  &lt;li&gt;S : Score (Probability) that account should be suspended&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Lets assume probabilities are given to us for the network as follows:
&lt;img src=&quot;https://github.com/anmolkapoor/inference-bayesian-networks-using-pgmpy-example-social-media-moderator/raw/master/images/bayes_net_final.jpg&quot; alt=&quot;Network&quot; /&gt;
&lt;img src=&quot;https://github.com/anmolkapoor/inference-bayesian-networks-using-pgmpy-example-social-media-moderator/raw/master/images/probs.png&quot; alt=&quot;Probs&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Lets create this bayes network in python using pgmpy library https://github.com/pgmpy/pgmpy .&lt;/strong&gt;&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;err&quot;&gt;!&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pip&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;install&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pgmpy&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;Requirement already satisfied: pgmpy in /anaconda3/lib/python3.7/site-packages (0.1.7)
Requirement already satisfied: scipy&amp;gt;=1.0.0 in /anaconda3/lib/python3.7/site-packages (from pgmpy) (1.2.1)
Requirement already satisfied: networkx&amp;lt;1.12,&amp;gt;=1.11 in /anaconda3/lib/python3.7/site-packages (from pgmpy) (1.11)
Requirement already satisfied: numpy&amp;gt;=1.14.0 in /anaconda3/lib/python3.7/site-packages (from pgmpy) (1.16.2)
Requirement already satisfied: decorator&amp;gt;=3.4.0 in /anaconda3/lib/python3.7/site-packages (from networkx&amp;lt;1.12,&amp;gt;=1.11-&amp;gt;pgmpy) (4.4.0)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;pgmpy.models&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;BayesianModel&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;pgmpy.factors.discrete&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;TabularCPD&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;pgmpy.inference&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;VariableElimination&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;numpy&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;bayesNet&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;BayesianModel&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;bayesNet&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;add_node&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;M&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;bayesNet&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;add_node&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;U&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;bayesNet&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;add_node&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;R&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;bayesNet&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;add_node&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;B&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;bayesNet&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;add_node&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;S&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;bayesNet&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;add_edge&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;M&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;R&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;bayesNet&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;add_edge&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;U&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;R&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;bayesNet&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;add_edge&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;B&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;R&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;bayesNet&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;add_edge&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;B&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;S&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;bayesNet&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;add_edge&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;R&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;S&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Adding CPDs for each node. A quick note is that while adding proabilities, we have to give FALSE values first.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;cpd_A&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;TabularCPD&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'M'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;values&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[[&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;95&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;mo&quot;&gt;05&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]])&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;cpd_U&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;TabularCPD&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'U'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;values&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[[&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;85&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;15&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]])&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;cpd_H&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;TabularCPD&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'B'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;values&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[[&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;90&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]])&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;cpd_S&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;TabularCPD&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'S'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;values&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[[&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.98&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;88&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;95&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;6&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;mo&quot;&gt;02&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;12&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;mo&quot;&gt;05&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;40&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]],&lt;/span&gt;
                   &lt;span class=&quot;n&quot;&gt;evidence&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'R'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'B'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;evidence_card&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;cpd_R&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;TabularCPD&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'R'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                   &lt;span class=&quot;n&quot;&gt;values&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[[&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.96&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;86&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;94&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;82&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;24&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;15&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;mo&quot;&gt;05&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;mo&quot;&gt;04&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;14&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;mo&quot;&gt;06&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;18&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;76&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;85&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;90&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;95&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]],&lt;/span&gt;
                   &lt;span class=&quot;n&quot;&gt;evidence&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'M'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'B'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'U'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;evidence_card&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;bayesNet&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;add_cpds&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cpd_A&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cpd_U&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cpd_H&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cpd_S&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cpd_R&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Checking if model is correctly added.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;bayesNet&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;check_model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;Model is correct.&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;Model is correct.
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Creating solver that uses variable elimination internally for inference.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;solver&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;VariableElimination&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;bayesNet&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Lets take some examples. For cross verification, we will be doing inference manually also using Bayes Theorem and Total Probability theorem.&lt;/p&gt;

&lt;h4 id=&quot;1-lets-find-proability-of-content-should-be-removed-from-the-platform&quot;&gt;1. Lets find proability of “Content should be removed from the platform”**&lt;/h4&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;P(R) 
=P(R|MBU)*P(M)*P(B)*P(U)+P(R|MBU)*P(M)*P(B)*P(!U)+P(R|MBU)*P(M)*P(!B)*P(U)
+P(R|MBU)*P(M)*P(!B)*P(!U)+P(R|MBU)*P(!M)*P(B)*P(U)+P(R|MBU)*P(!M)*P(B)*P(!U)
+P(R|MBU)*P(!M)*P(!B)*P(U)+P(R|MBU)*P(!M)*P(!B)*P(!U) --- [Using total probability theorem as R depends on M, B, U]
=0.95*0.05*0.1*0.15+0.9*0.05*0.1*0.85+0.85*0.05*0.9*0.15
+0.76*0.05*0.9*0.85+0.18*0.95*0.1*0.15+0.06*0.95*0.1*0.85
+0.14*0.95*0.9*0.15+0.04*0.95*0.9*0.85
=0.09378
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Using pgmpy library:&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;result&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;solver&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;query&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;variables&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'R'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;R&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;result&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'R'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;values&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;R 0.09378000000000002
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h4 id=&quot;2-lets-find-probability-of-content-should-be-removed-from-platform-given-our-ml-model-flags-it&quot;&gt;2. Lets find probability of “Content should be removed from platform given our ML model flags it”&lt;/h4&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;P(R|A) 
= P(R|AHU) * P(H) * P(U) + P (R|AH!U) * P(H) *P(!U) + P(R|A!HU) 
* P(!H) * P(U)+ P(R|A!H!U) * P(!H) * P(!U)                      -------- [ Using Total Probability theorem ]
=0.95*0.1*0.15 + 0.9*0.1*0.85 +0.85*0.9*0.15 + 0.76*0.9*0.85
=0.7869
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Now, Using pgmpy libary:&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;result&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;solver&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;query&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;variables&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'R'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;evidence&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'M'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;})&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;R| M&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;result&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'R'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;values&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;

&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;R| M 0.7869
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h4 id=&quot;pgmpy-can-also-find-complex-proability-inference-considering-dependent-and-independent-variable-considering-something-is-given&quot;&gt;Pgmpy can also find complex proability inference considering dependent and independent variable considering something is given.&lt;/h4&gt;
&lt;h4 id=&quot;for-example-we-can-find-account-should-be-suspended-given-it-was-suspened-before&quot;&gt;For example, we can find “Account should be suspended given it was suspened before”&lt;/h4&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;result&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;solver&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;query&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;variables&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'S'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;evidence&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'B'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;})&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;S| B&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;result&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'S'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;values&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;S| B 0.15345299999999998
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h4 id=&quot;model-has-other-features-such-as-it-can-also-find-dependencies-between-the-variables-example&quot;&gt;Model has other features such as it can also find dependencies between the variables. Example:&lt;/h4&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;bayesNet&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;get_independencies&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;(M _|_ U, B)
(M _|_ B | U)
(M _|_ U | B)
(M _|_ S | R, B)
(M _|_ S | R, U, B)
(U _|_ M, B)
(U _|_ B | M)
(U _|_ M | B)
(U _|_ S | R, B)
(U _|_ S | M, R, B)
(B _|_ M, U)
(B _|_ U | M)
(B _|_ M | U)
(S _|_ M, U | R, B)
(S _|_ U | M, R, B)
(S _|_ M | R, U, B)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;Completed.&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;Completed.
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;</content><author><name>Anmol Kapoor</name></author><summary type="html">In this quick notebook, we will be discussing Bayesian Statisitcs over Bayesian Networks and Inferencing them using Pgmpy Python library. Bayesian statistics is a theory in the field of statistics based on the Bayesian interpretation of probability where probability expresses a degree of belief in an event, which can change as new information is gathered, rather than a fixed value based upon frequency or propensity.Bayesian statistical methods use Bayes’ theorem to compute and update probabilities after obtaining new data. Bayes’ theorem describes the conditional probability of an event based on data as well as prior information or beliefs about the event or conditions related to the event.</summary></entry><entry><title type="html">Technical Analysis with Indicators and building a ML based trading strategy (Part 2 of 2)</title><link href="http://anmolkapoor.in/2019/05/02/Technical-Analysis-With-Indicators-And-Building-ML-Based-Trading-Strategy-Part-2/" rel="alternate" type="text/html" title="Technical Analysis with Indicators and building a ML based trading strategy (Part 2 of 2)" /><published>2019-05-02T00:00:00+05:30</published><updated>2019-05-02T00:00:00+05:30</updated><id>http://anmolkapoor.in/2019/05/02/Technical-Analysis-With-Indicators-And-Building-ML-Based-Trading-Strategy-Part-2</id><content type="html" xml:base="http://anmolkapoor.in/2019/05/02/Technical-Analysis-With-Indicators-And-Building-ML-Based-Trading-Strategy-Part-2/">&lt;p&gt;Part 2 of the Technical indicator series with quick recap of technical indicators, formulating trading problem as machine learning problem and comparative analysis between benchmark, manual rule based strategy and machine learning strategy&lt;/p&gt;

&lt;p&gt;A quick recap from the last post, we established, technical indicators as heuristic based on the price, volume, or open interest of a security or contract. By analysing historical data, technical analysts use indicators to predict future price movements. Using these predictions, analysts create strategies that they would apply to trade a security in order to make profit. We looked upon three such indicators : Simple Moving average, Momentum and Bollinger Bands®. We created a rule based manual strategy strategy and checked it portfolio performance.&lt;/p&gt;

&lt;p&gt;In this post, we will be discussing:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Understanding Random Decision Tree and Bagging.&lt;/li&gt;
  &lt;li&gt;How to formulate the trading problem as machine learning problem.&lt;/li&gt;
  &lt;li&gt;Train our machine learning model and create a machine learning strategy called as StrategyLearner.&lt;/li&gt;
  &lt;li&gt;Comparative Analysis of Benchmark, Manual Strategy and Strategy Learner.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;decision-trees-and-bagging&quot;&gt;Decision Trees and Bagging&lt;/h2&gt;
&lt;p&gt;Decision tree is a type of supervised learning algorithm (having a pre-defined target variable) that is mostly used in classification problems. It works for both categorical and continuous input and output variables. In this technique, we split the population or sample into two or more homogeneous sets (or sub-populations) based on most significant splitter / differentiator in input variables.
Types of decision tree is based on the type of target variable we have. It can be of two types:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Categorical Variable Decision Tree: Decision Tree which has categorical target variable then it called as categorical variable decision tree. E.g.:-  Target variable was “Is it raining today” i.e. YES or NO.&lt;/li&gt;
  &lt;li&gt;Continuous Variable Decision Tree: Decision Tree has continuous target variable then it is called as Continuous Variable Decision Tree.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;a href=&quot;https://github.com/anmolkapoor/building-ml-trading-strategy-using-decision-tree-with-bagging/raw/master/images/decision_tree.png&quot;&gt;&lt;img src=&quot;https://github.com/anmolkapoor/building-ml-trading-strategy-using-decision-tree-with-bagging/raw/master/images/decision_tree.png&quot; alt=&quot;Decision Tree&quot; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;h4 id=&quot;advantages-&quot;&gt;Advantages :&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;Easy to Understand&lt;/li&gt;
  &lt;li&gt;Easy to generate rules&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;disadvantages&quot;&gt;Disadvantages:&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;May suffer from overfitting.&lt;/li&gt;
  &lt;li&gt;Classifies by rectangle partitioning.&lt;/li&gt;
  &lt;li&gt;Can be quite large, pruning is necessary.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;bagging-or-bootstrap-aggregation&quot;&gt;Bagging or Bootstrap Aggregation&lt;/h3&gt;
&lt;p&gt;Bootstrap aggregating, also called bagging, is a machine learning ensemble meta-algorithm designed to improve the stability and accuracy of machine learning algorithms used in statistical classification and regression. It also reduces variance and helps to avoid overfitting. Although it is usually applied to decision tree methods, it can be used with any type of method. Bagging is a special case of the model averaging approach.&lt;/p&gt;

&lt;h3 id=&quot;random-decision-trees&quot;&gt;Random Decision Trees&lt;/h3&gt;
&lt;p&gt;Algorithms to create decision trees try to choose and split the feature which divides into 2 segments with maximum information gain. Information gain calculation can be complex compute problem which can increase the training time when using multiple decision trees in bagging. For our strategy we will be using Random Decision Trees, which at every step randomly chooses the feature to split on during training. This much faster and can give almost similar accuracy when bagged with multiple such random decision trees.&lt;/p&gt;

&lt;h2 id=&quot;steps-to-frame-the-trading-problem-as-machine-learning-problem&quot;&gt;Steps to frame the trading problem as machine learning problem&lt;/h2&gt;
&lt;p&gt;For a learning problem, the system should have a train and a test scenario. I have used the BagLearner (leaf_size =5, bags=20) with RTLearner for my StrategyLearner.&lt;/p&gt;

&lt;p&gt;To frame the training procedure, following steps were taken:&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;Get Symbol data using Utility for in-sample period.&lt;/li&gt;
  &lt;li&gt;Get values for the Indicators for the prices.&lt;/li&gt;
  &lt;li&gt;Combine to form X_train data set.&lt;/li&gt;
  &lt;li&gt;With a chosen N value, create Y_train data set. Using price change ratio:&lt;/li&gt;
&lt;/ol&gt;

&lt;blockquote&gt;
  &lt;p&gt;price_change = (price[t+N] - price[t] ) / price[t]&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Classify into:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;+1 or “LONG” for day = t&lt;/li&gt;
  &lt;li&gt;-1 or “SHORT” for day = t&lt;/li&gt;
  &lt;li&gt;0 or “CASH” in case non of a) and b)&lt;/li&gt;
&lt;/ul&gt;

&lt;ol&gt;
  &lt;li&gt;Train BagLearner using X_train and Y_train data with addEvidence procedure.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;To frame the test procedure, following steps were taken:&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;Get Symbol data using Utility for out-sample period.&lt;/li&gt;
  &lt;li&gt;Get values for the Indicators for the prices.&lt;/li&gt;
  &lt;li&gt;Combine to form X_test data set.&lt;/li&gt;
  &lt;li&gt;Test and generate Y_test using query procedure over BagLearner.&lt;/li&gt;
  &lt;li&gt;Convert +1, -1 and 0 to trades with portfolio position always +1000, 0 or -1000.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Quick Recap of Indicators used:&lt;/p&gt;

&lt;h5 id=&quot;1-simple-moving-average-sma&quot;&gt;1. Simple Moving Average (SMA)&lt;/h5&gt;
&lt;p&gt;SMA is the moving average calculated by sum of adjusted closing price of a stock over the window and diving over size of the window.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;SMA[t] = price[t − N: t] . mean()&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h5 id=&quot;2-momentum&quot;&gt;2. Momentum&lt;/h5&gt;
&lt;p&gt;Momentum refers to the rate of change in the adjusted close price of the s. It can be calculated :&lt;/p&gt;
&lt;blockquote&gt;
  &lt;p&gt;Momentum[t] = (price[t] / price[t − N])-1&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h5 id=&quot;3-bollinger-bands&quot;&gt;3. Bollinger Bands®&lt;/h5&gt;
&lt;p&gt;Bollinger Bands (developed by John Bollinger) is the plot of two bands two sigma away from the simple moving average. They can be calculated as:&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;upper_band = sma + standard_deviation * 2 
lower_band = sma - standard_deviation * 2&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h3 id=&quot;comparative-analysis&quot;&gt;Comparative analysis&lt;/h3&gt;
&lt;p&gt;For all three : StrategyLearner, ManualStrategy and Benchmark&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Sample data used is in-sample data from January 1,2008 to December 31, 2009&lt;/li&gt;
  &lt;li&gt;Start value as 100000.&lt;/li&gt;
  &lt;li&gt;Impact used as 0.00 and Commission used as 0.00&lt;/li&gt;
  &lt;li&gt;Benchmark if we buy 1000 JPM shares and hold them throughout the period.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;For StrategyLearner, parameters:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;BagLearner with RT Learner. Bags = 20&lt;/li&gt;
  &lt;li&gt;RTLearner, leaf_size = 5&lt;/li&gt;
  &lt;li&gt;Mode was used in RTLearner at leaves.&lt;/li&gt;
  &lt;li&gt;Mode was used in BagLearner to take vote between all RTLearner in the bag&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;a href=&quot;https://github.com/anmolkapoor/building-ml-trading-strategy-using-decision-tree-with-bagging/raw/master/images/experiment_1_graph.png&quot;&gt;&lt;img src=&quot;https://github.com/anmolkapoor/building-ml-trading-strategy-using-decision-tree-with-bagging/raw/master/images/experiment_1_graph.png&quot; alt=&quot;Results Image&quot; /&gt;&lt;/a&gt;
As we can see from the plot, Manual Strategy is little better than Benchmark, but Strategy learner using machine learned strategy is able to outperform. Statistical results comparing the three:&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt; &lt;/th&gt;
      &lt;th&gt;Benchmark&lt;/th&gt;
      &lt;th&gt;ManualStrategy&lt;/th&gt;
      &lt;th&gt;StrategyLearner&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;Cumulative return&lt;/td&gt;
      &lt;td&gt;0.0123&lt;/td&gt;
      &lt;td&gt;0.4641&lt;/td&gt;
      &lt;td&gt;2.4648&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Standard Deviation&lt;/td&gt;
      &lt;td&gt;0.017004&lt;/td&gt;
      &lt;td&gt;0.012419&lt;/td&gt;
      &lt;td&gt;0.007978&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Average Daily Return&lt;/td&gt;
      &lt;td&gt;0.000168&lt;/td&gt;
      &lt;td&gt;0.000833&lt;/td&gt;
      &lt;td&gt;0.002500&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Final Portfolio Value&lt;/td&gt;
      &lt;td&gt;101,230.00&lt;/td&gt;
      &lt;td&gt;146,410.00&lt;/td&gt;
      &lt;td&gt;346,480.00&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;This concludes our series of introduction to technical indicators, creating a manual rule base strategy using them and creating a ML based strategy to learn those rules. At every step we compared and analyse our strategies and their performance.&lt;/p&gt;</content><author><name>Anmol Kapoor</name></author><summary type="html">Part 2 of the Technical indicator series with quick recap of technical indicators, formulating trading problem as machine learning problem and comparative analysis between benchmark, manual rule based strategy and machine learning strategy</summary></entry><entry><title type="html">Technical Analysis with Indicators and building a ML based trading strategy (Part 1 of 2)</title><link href="http://anmolkapoor.in/2019/05/01/Technical-Analysis-With-Indicators-And-Building-Rule-Based-Trading-Strategy-Part-1/" rel="alternate" type="text/html" title="Technical Analysis with Indicators and building a ML based trading strategy (Part 1 of 2)" /><published>2019-05-01T00:00:00+05:30</published><updated>2019-05-01T00:00:00+05:30</updated><id>http://anmolkapoor.in/2019/05/01/Technical-Analysis-With-Indicators-And-Building-Rule-Based-Trading-Strategy-Part-1</id><content type="html" xml:base="http://anmolkapoor.in/2019/05/01/Technical-Analysis-With-Indicators-And-Building-Rule-Based-Trading-Strategy-Part-1/">&lt;p&gt;Technical indicators are heuristic or mathematical calculations based on the price, volume, or open interest of a security or contract used by traders who follow technical analysis. By analysing historical data, technical analysts use indicators to predict future price movements. Using these predictions, analysts create strategies that they would apply to trade a security in order to make profit.&lt;/p&gt;

&lt;p&gt;In this post, we will be discussing:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Three examples of Technical indicators, namely Simple moving average, Momentum and Bollinger Bands®.&lt;/li&gt;
  &lt;li&gt;Strategy and how to view them as trade orders.&lt;/li&gt;
  &lt;li&gt;Create a Theoretically optimal strategy if we can see future stock prices.&lt;/li&gt;
  &lt;li&gt;Create a Manual Strategy based on indicators.&lt;/li&gt;
  &lt;li&gt;Compare and  analysis of two strategies.&lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
  &lt;p&gt;Since the above indicators are based on rolling window, we have taken 30 Days as the rolling window size.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h3 id=&quot;simple-moving-average&quot;&gt;Simple Moving average&lt;/h3&gt;

&lt;p&gt;SMA is the moving average calculated by sum of adjusted closing price of a stock over the window and diving over size of the window.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;SMA[t] = price[t − N: t] . mean()&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;SMA can be used as a proxy the true value of the company stock. For large deviations from the price, we can expect the price to come back to the SMA over a period of time. This can create a BUY and SELL opportunity when optimised over a threshold.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://github.com/anmolkapoor/technical-analysis-using-indicators-and-building-rule-based-strategy/raw/master/images/Normalized%20Price%20%26%20Simple%20Moving%20Average.png&quot;&gt;&lt;img src=&quot;https://github.com/anmolkapoor/technical-analysis-using-indicators-and-building-rule-based-strategy/raw/master/images/Normalized%20Price%20%26%20Simple%20Moving%20Average.png&quot; alt=&quot;SMA Chart&quot; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;h3 id=&quot;momentum&quot;&gt;Momentum&lt;/h3&gt;

&lt;p&gt;Momentum refers to the rate of change in the adjusted close price of the s. It can be calculated :&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;Momentum[t] = (price[t] / price[t − N])-1&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;The value of momentum can be used an indicator, and can be used as a intuition that future price may follow the inertia. That means that if a stock price is going up with a high momentum, we can use this as a signal for BUY opportunity as it can go up further in future.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://github.com/anmolkapoor/technical-analysis-using-indicators-and-building-rule-based-strategy/raw/master/images/Normalized%20Price%20%26%20Momentum.png&quot;&gt;&lt;img src=&quot;https://github.com/anmolkapoor/technical-analysis-using-indicators-and-building-rule-based-strategy/raw/master/images/Normalized%20Price%20%26%20Momentum.png&quot; alt=&quot;Momentum Chart&quot; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;h3 id=&quot;bollinger-bands&quot;&gt;Bollinger Bands®&lt;/h3&gt;

&lt;p&gt;Bollinger Bands (developed by John Bollinger) is the plot of two bands two sigma away from the simple moving average. They can be calculated as:&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;upper_band = sma + standard_deviation * 2&lt;/p&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;p&gt;lower_band = sma - standard_deviation * 2&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;If we plot the Bollinger Bands with the price for a time period:&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://github.com/anmolkapoor/technical-analysis-using-indicators-and-building-rule-based-strategy/raw/master/images/Normalized%20Price%20%26%20Bollinger%20bands.png&quot;&gt;&lt;img src=&quot;https://github.com/anmolkapoor/technical-analysis-using-indicators-and-building-rule-based-strategy/raw/master/images/Normalized%20Price%20%26%20Bollinger%20bands.png&quot; alt=&quot;BB Chart&quot; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;We can find trading opportunity as SELL where price is entering the upper band from outside the upper band, and BUY where price is lower than the lower band and moving towards the SMA from outside. This movement inlines with our indication that price will oscillate from SMA, but will come back to SMA and can be used as trading opportunities.&lt;/p&gt;

&lt;h1 id=&quot;strategy-and-trade-orders&quot;&gt;Strategy and Trade orders&lt;/h1&gt;
&lt;p&gt;For our discussion, let us assume we are trading a stock in market over a period of time. Trading of a stock, in its simplistic form means we can either sell, buy or hold our stocks in portfolio. These commands issued are orders that let us trade the stock over the exchange. Thus, these trade orders can be of type:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;SHORT  or SELL . eg: SHORT JPM 1000&lt;/li&gt;
  &lt;li&gt;LONG or BUY. eg; LONG JPM 1000&lt;/li&gt;
  &lt;li&gt;HOLD. which is holding the stocks in our portfolio.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;For simplicity of discussion, lets assume, we can only issue these three commands SHORT, LONG and HOLD for our stock JPM, and our portfolio can either be in these three states at a given time:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;+1000 ( We have 1000 JPM stocks in portfolio)&lt;/li&gt;
  &lt;li&gt;0 ( We have no JPM stocks in portfolio)&lt;/li&gt;
  &lt;li&gt;-1000 (We have short 1000 JPM stocks and attributed them in our portfolio)&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;theoretically-optimal-strategy&quot;&gt;Theoretically Optimal Strategy&lt;/h1&gt;

&lt;p&gt;Lets assume we can foresee the future price and our tasks is create a strategy that can make profit. A simple strategy is to sell as much as there is possibility in the portfolio ( SHORT till portfolio reaches -1000) and if price is going up in future buy as much as there is possibility in the portfolio( LONG till portfolio reaches +1000)&lt;/p&gt;

&lt;p&gt;Pseudo code:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;
Is_price_going_up = price[today+1] - price[today]

if is_price_going_up:
    do_buy_trade
else:
    do_sell_trade

&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Results:&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;Date Range: 2008-01-01 to 2009-12-31&lt;/p&gt;
&lt;/blockquote&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt; &lt;/th&gt;
      &lt;th&gt;Theoretical Strategy&lt;/th&gt;
      &lt;th&gt;Benchmark&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;Cumulative return&lt;/td&gt;
      &lt;td&gt;5.7861&lt;/td&gt;
      &lt;td&gt;0.0123&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Stdev of daily returns&lt;/td&gt;
      &lt;td&gt;0.00454782319791&lt;/td&gt;
      &lt;td&gt;0.0170043662712&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Average of daily returns&lt;/td&gt;
      &lt;td&gt;0.00381678615086&lt;/td&gt;
      &lt;td&gt;0.000168086978191&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Final Portfolio Value&lt;/td&gt;
      &lt;td&gt;678610.0&lt;/td&gt;
      &lt;td&gt;101230.0&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;&lt;a href=&quot;https://github.com/anmolkapoor/technical-analysis-using-indicators-and-building-rule-based-strategy/raw/master/images/TheoreticallyOptimalStrategy.png&quot;&gt;&lt;img src=&quot;https://github.com/anmolkapoor/technical-analysis-using-indicators-and-building-rule-based-strategy/raw/master/images/TheoreticallyOptimalStrategy.png&quot; alt=&quot;Theoritical Chart&quot; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;h3 id=&quot;manual-rule-based-trader&quot;&gt;Manual Rule-Based Trader&lt;/h3&gt;

&lt;p&gt;Now consider we did not have power to see the future value of stock (that will be the case always), can we create a strategy that will use the three indicators described to predict the future. Let’s call it ManualStrategy which will be based on some rules over our indicators. We have applied the following strategy using 3 indicators : Bollinger Bands, Momentum and Volatility using Price Vs SMA.&lt;/p&gt;

&lt;p&gt;Strategy:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;
If price_yesterday was above upper_band_yesterday and price_today is below upper_band_today:
    do_sell_trade
Else if price_yesterday was below lower_band_yesterday and price_today is above lower_band_today:
    do_buy_trade
Else if price_today &amp;gt; sma_today and difference(price_today, sma_today)&amp;gt; threshold:
    do_sell_trade
Else if price_today&amp;lt;sma_today and difference(sma_today,price_today) &amp;gt; threshold:
    do_buy_trade
Else if momentum_today &amp;gt; threshold_positive
    do_buy_trade
Else if momentum_today&amp;lt;theshold_negative
    do_sell_trade
Else No_trade

&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Results:&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;Date Range: 2008-01-01 to 2009-12-31&lt;/p&gt;
&lt;/blockquote&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt; &lt;/th&gt;
      &lt;th&gt;Manual Strategy&lt;/th&gt;
      &lt;th&gt;Benchmark&lt;/th&gt;
      &lt;th&gt; &lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;Cumulative return&lt;/td&gt;
      &lt;td&gt;0.358969602112&lt;/td&gt;
      &lt;td&gt;0.0123&lt;/td&gt;
      &lt;td&gt;\&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Stdev of daily returns&lt;/td&gt;
      &lt;td&gt;0.0129419160091&lt;/td&gt;
      &lt;td&gt;0.0170043662712&lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Average of daily returns&lt;/td&gt;
      &lt;td&gt;0.000692144738531&lt;/td&gt;
      &lt;td&gt;0.000168086978191&lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Final Portfolio Value&lt;/td&gt;
      &lt;td&gt;135884.05&lt;/td&gt;
      &lt;td&gt;101230.0&lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;&lt;a href=&quot;https://github.com/anmolkapoor/technical-analysis-using-indicators-and-building-rule-based-strategy/raw/master/images/ManualStrategy-Train.png&quot;&gt;&lt;img src=&quot;https://github.com/anmolkapoor/technical-analysis-using-indicators-and-building-rule-based-strategy/raw/master/images/ManualStrategy-Train.png&quot; alt=&quot;ManualStrategy&quot; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;h1 id=&quot;comparative-analysis&quot;&gt;Comparative Analysis&lt;/h1&gt;

&lt;p&gt;Here are the statistics comparing in-sample data:&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;Date: 2008-01-01 to 2009-12-31&lt;/p&gt;
&lt;/blockquote&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt; &lt;/th&gt;
      &lt;th&gt;Manual Strategy&lt;/th&gt;
      &lt;th&gt;Benchmark&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;Cumulative return&lt;/td&gt;
      &lt;td&gt;0.358969602112&lt;/td&gt;
      &lt;td&gt;0.0123&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Stdev of daily returns&lt;/td&gt;
      &lt;td&gt;0.0129419160091&lt;/td&gt;
      &lt;td&gt;0.0170043662712&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Average of daily returns&lt;/td&gt;
      &lt;td&gt;0.000692144738531&lt;/td&gt;
      &lt;td&gt;0.000168086978191&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Final Portfolio Value&lt;/td&gt;
      &lt;td&gt;135884.05&lt;/td&gt;
      &lt;td&gt;101230.0&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;For out-sample:&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;Date: 2010-01-01 2011-12-31&lt;/p&gt;
&lt;/blockquote&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt; &lt;/th&gt;
      &lt;th&gt;Manual Strategy&lt;/th&gt;
      &lt;th&gt;Benchmark&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;Cumulative return&lt;/td&gt;
      &lt;td&gt;0.0111025547427&lt;/td&gt;
      &lt;td&gt;-0.0834&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Stdev of daily returns&lt;/td&gt;
      &lt;td&gt;0.00832245137396&lt;/td&gt;
      &lt;td&gt;0.0084810074988&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Average of daily returns&lt;/td&gt;
      &lt;td&gt;5.6467518872e-05&lt;/td&gt;
      &lt;td&gt;-0.000137203160195\&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Final Portfolio Value&lt;/td&gt;
      &lt;td&gt;101100.65&lt;/td&gt;
      &lt;td&gt;91660.0&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;h4 id=&quot;why-there-is-a-difference-in-performance&quot;&gt;Why there is a difference in performance:&lt;/h4&gt;

&lt;p&gt;The manual strategy works well for the train period as we were able to tweak the different thresholds like window size, buy and selling threshold for momentum and volatility. The tweaked parameters did not work very well. Our bets on a large window size was not correct and even though the price went up, the huge lag in reflection on SMA and Momentum, was not able to give correct BUY and SELL opportunity on time.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://github.com/anmolkapoor/technical-analysis-using-indicators-and-building-rule-based-strategy/raw/master/images/ManualStrategy-Test.png&quot;&gt;&lt;img src=&quot;https://github.com/anmolkapoor/technical-analysis-using-indicators-and-building-rule-based-strategy/raw/master/images/ManualStrategy-Test.png&quot; alt=&quot;ManualStrategy-test&quot; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;h5 id=&quot;now-that-we-have-found-that-our-rule-based-strategy-was-not-very-optimum-can-we-apply-machine-learning-to-learn-optimal-rules-and-achieve-better-results&quot;&gt;Now that we have found that our rule based strategy was not very optimum, can we apply machine learning to learn optimal rules and achieve better results.&lt;/h5&gt;
&lt;p&gt;&lt;a href=&quot;/2019/05/02/Technical-Analysis-With-Indicators-And-Building-ML-Based-Trading-Strategy-Part-2/&quot;&gt;Read the next part of the series to create a machine learning based strategy over technical indicators and its comparative analysis over the rule based strategy&lt;/a&gt;.&lt;/p&gt;</content><author><name>Anmol Kapoor</name></author><summary type="html">Technical indicators are heuristic or mathematical calculations based on the price, volume, or open interest of a security or contract used by traders who follow technical analysis. By analysing historical data, technical analysts use indicators to predict future price movements. Using these predictions, analysts create strategies that they would apply to trade a security in order to make profit.</summary></entry><entry><title type="html">Arxiv-topics - Explore &amp;amp; Discover Research Papers on Arxiv repository using Topics Learned from Data</title><link href="http://anmolkapoor.in/2019/03/19/Explore-Arxiv-Repository-Using-Gensim-LDA-Topic-Modelling/" rel="alternate" type="text/html" title="Arxiv-topics - Explore &amp; Discover Research Papers on Arxiv repository using Topics Learned from Data" /><published>2019-03-19T00:00:00+05:30</published><updated>2019-03-19T00:00:00+05:30</updated><id>http://anmolkapoor.in/2019/03/19/Explore-Arxiv-Repository-Using-Gensim-LDA-Topic-Modelling</id><content type="html" xml:base="http://anmolkapoor.in/2019/03/19/Explore-Arxiv-Repository-Using-Gensim-LDA-Topic-Modelling/">&lt;p&gt;&lt;a href=&quot;https://arxiv.org/&quot;&gt; Arxiv repository https://arxiv.org/ &lt;/a&gt; hosts 1.5m academic papers, and users add over 10K papers per month. Keeping track of trends is challenging as it is limited to keyword search, and does not let users track and explore content based on themes that capture relationships beyond shared words, or recommend content from this perspective. This challenged us to use unsupervised learning to learn topics to summarise documents, and let users explore and find research papers on similar topics.&lt;/p&gt;

&lt;p&gt;Our approach is divided in three steps:&lt;/p&gt;

&lt;p&gt;First, For the topic discovery we used LDA topic model. In simple terms, with given documents and their words, the purpose of LDA is to learn the representation of fixed number of topics from the corpus and their distribution. We also experimented with  with other topic models such as LSA, contrasted their result and found LDA topics to be more accurate and interpretable.&lt;/p&gt;

&lt;p&gt;Second, At the core of our web application, we use pyLDAvis, to visualize and let user explore individual topics and its associated terms.
Whats new in our approach is third step which now allow user to find research paper similar to its topic mix. For example, a user reading research paper on theme of Computer vision and Human Computer Interaction. can easily find another paper around same theme.&lt;/p&gt;

&lt;p&gt;For experiments we  download 26,000 research papers through &lt;a href=&quot;https://arxiv.org/help/api/index&quot;&gt;Arxiv api https://arxiv.org/help/api/index&lt;/a&gt;, lemmatised them, applied stemming, and examined top 1000 keywords manually&lt;/p&gt;

&lt;p&gt;To evaluate a topic model, we calculated Topic coherence which is measures of topic consistency. Since it is unsupervised learning for our experiments we generated visualisations of over a topic range from 3 to 100. Experiment resulted in topics which are diverse yet well defined and can be given well defined names like Language, LifeScience, Theory etc.&lt;/p&gt;

&lt;h2 id=&quot;quick-walkthrough-video-with-demo&quot;&gt;Quick walkthrough video with demo&lt;/h2&gt;
&lt;h6 id=&quot;3-min-watch&quot;&gt;(3 min watch)&lt;/h6&gt;
&lt;hr /&gt;
&lt;p&gt;&lt;a href=&quot;https://www.youtube.com/watch?v=grQj8xCZtdo&quot; title=&quot;Quick walkthrough video with demo  - Click to Watch!&quot;&gt;&lt;img src=&quot;https://raw.githubusercontent.com/anmolkapoor/explore-arxiv-using-lda-gensim-topic-modelling/master/documents/youtube-video-screenshot.png&quot; alt=&quot;You tube screenshot&quot; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&quot;running-app-demo-on-heroku&quot;&gt;Running app demo (on Heroku)&lt;/h2&gt;
&lt;h6 id=&quot;please-allow-30-sec-to-wake-up-sleepingzzz-dyno&quot;&gt;(Please allow 30 sec to wake up sleeping(zzz…) dyno&lt;/h6&gt;
&lt;hr /&gt;
&lt;p&gt;&lt;a href=&quot;https://boiling-thicket-31500.herokuapp.com/&quot; title=&quot;Demo on Heroku  - Click to view!&quot;&gt;&lt;img src=&quot;https://raw.githubusercontent.com/anmolkapoor/explore-arxiv-using-lda-gensim-topic-modelling/master/documents/demo-screenshot.png&quot; alt=&quot;Demo screenshot&quot; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&quot;detailed-project-details&quot;&gt;Detailed project details&lt;/h2&gt;
&lt;h6 id=&quot;15-min-read&quot;&gt;15 min read&lt;/h6&gt;
&lt;hr /&gt;
&lt;p&gt;&lt;a href=&quot;https://github.com/anmolkapoor/explore-arxiv-using-lda-gensim-topic-modelling/blob/master/documents/report.pdf&quot;&gt;Detailed  Report PDF &lt;/a&gt;&lt;/p&gt;</content><author><name>Anmol Kapoor</name></author><summary type="html">Arxiv repository https://arxiv.org/ hosts 1.5m academic papers, and users add over 10K papers per month. Keeping track of trends is challenging as it is limited to keyword search, and does not let users track and explore content based on themes that capture relationships beyond shared words, or recommend content from this perspective. This challenged us to use unsupervised learning to learn topics to summarise documents, and let users explore and find research papers on similar topics.</summary></entry><entry><title type="html">Kullback-Leibler Divergence Explained</title><link href="http://anmolkapoor.in/2019/03/16/kullback-leibler-divergence-explained/" rel="alternate" type="text/html" title="Kullback-Leibler Divergence Explained" /><published>2019-03-16T00:00:00+05:30</published><updated>2019-03-16T00:00:00+05:30</updated><id>http://anmolkapoor.in/2019/03/16/kullback-leibler-divergence-explained</id><content type="html" xml:base="http://anmolkapoor.in/2019/03/16/kullback-leibler-divergence-explained/">&lt;p&gt;This post is about comparing two probablistic distributions and the measure of loss of infromation that will happen if one is represented by other. In real world, proabibilty distributions depicts the probability of different variables that can be taken by a variable. For this example, we will consider probability distribution of decrete values of a variable. To relate to a situation lets go through an example.&lt;/p&gt;

&lt;p&gt;Suppose in galaxy far far away, R2D2 was given a task by princess &amp;lt;#todo&amp;gt; to store th plans for the death star. These plans are the possible positions of the target quardrant, firing on which can detroy death star. Pricess gives the task to R2D2 to transmit this information to the rebels.&lt;/p&gt;

&lt;p&gt;The data looks like this:&lt;/p&gt;

&lt;p&gt;The above data is about 6 mutually exculsive places and their success count (each instanc)&lt;/p&gt;

&lt;p&gt;In its escape, R2D2 damages its superior communication ability and moved down to transmit only 2 variables of information. Luckily it these two variables are enough to transmit two other well known proabability distributions : Descrete Uniform distribution and Binomial distribution&lt;/p&gt;

&lt;p&gt;Discrete Uniform distrubtion, which is well understood by the rebels show&lt;/p&gt;</content><author><name>Anmol Kapoor</name></author><summary type="html">This post is about comparing two probablistic distributions and the measure of loss of infromation that will happen if one is represented by other. In real world, proabibilty distributions depicts the probability of different variables that can be taken by a variable. For this example, we will consider probability distribution of decrete values of a variable. To relate to a situation lets go through an example.</summary></entry></feed>